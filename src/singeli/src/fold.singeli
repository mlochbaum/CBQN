include './base'
if (hasarch{'AVX2'}) {
  include './sse'
  include './avx'
  include './avx2'
} else if (hasarch{'X86_64'}) {
  include './sse2'
} else if (hasarch{'AARCH64'}) {
  include './neon'
}
include './mask'

def opsh64{op}{v:[4]f64, perm} = op{v, shuf{[4]u64, v, perm}}
def opsh32{op}{v:[2]f64, perm} = op{v, shuf{[4]u32, v, perm}}
def mix{op, v:[4]f64 & hasarch{'AVX'}} = { def sh=opsh64{op}; sh{sh{v, 4b2301}, 4b1032} }
def mix{op, v:[2]f64 & hasarch{'X86_64'}} = opsh32{op}{v, 4b1032}

def reduce_pairwise{op, plog, x:*T, len, init:T} = {
  # Pairwise combination to shorten dependency chains
  def pairwise{p, i, k} = (if (k==0) { load{p,i} } else {
    def l = k-1
    op{pairwise{p, i       , l},
       pairwise{p, i+(1<<l), l}}
  })
  f:= len >> plog
  r:= init
  @for (i to f) r = op{r, pairwise{x+(i<<plog), 0, plog}}
  @for (x over i from f<<plog to len) r = op{r, x}
  r
}

fn fold_idem{T==f64, op}(x:*T, len:u64) : T = {
  def bulk = arch_defvw/width{T}
  def V = [bulk]T
  xv:= *V ~~ x
  r:V = [bulk]f64**0
  assert{len > 0}
  if (len<bulk) {
    # Can't overlap like the long case
    r = load{xv}
    if (bulk>2) {
      assert{(bulk==4) & hasarch{'AVX'}}
      if (len > 1) {
        if (len > 2) r = opsh64{op}{r, 4b2222}
                     r = opsh64{op}{r, 4b1111}
      }
    }
  } else {
    i:= load{*V ~~ (x+len-bulk)}
    r0:= reduce_pairwise{op, 2, xv, (len-1)/bulk, i}
    if (hasarch{'AARCH64'}) return{vfold{op, r0}}
    else r = mix{op, r0}
  }
  extract{r, 0}
}

export{'simd_fold_min_f64', fold_idem{f64,min}}
export{'simd_fold_max_f64', fold_idem{f64,max}}

fn fold_assoc_0{T==f64, op}(x:*T, len:u64) : T = {
  def bulk = arch_defvw/width{T}
  def V = [bulk]T
  xv:= *V ~~ x
  e:= len / bulk
  i:= load{xv, e} & (V~~maskOf{V, len % bulk})
  r:= reduce_pairwise{op, 2, xv, e, i}
  if (hasarch{'AARCH64'}) vfold{op, r}
  else extract{mix{op, r}, 0}
}
export{'simd_sum_f64', fold_assoc_0{f64,+}}

def insert_assoc_reg{T, op, id:T, x0:*void, len:u64, wid:u64} = {
  def n = 6
  def vw = arch_defvw / width{T}
  def V = [vw]T
  total := len*wid             # Total elements
  set := len; step := total; numr:u64 = 0
  if (total > n*vw) {
    set  = n*vw / wid          # Rows in one set of vectors
    assert{set > 0}
    step = set * wid           # Elements in one set
    numr = cdiv{total-n*vw, step} * step # Elements handled by main loop
  }

  # rv: masked load of up to n vectors starting at end (rem elements)
  x := *T~~x0; end := x + numr
  rem := total - numr
  rv  := undef{V, n}
  idv := V**id
  def id_labels = @collect (n) makelabel{}
  each{{g} => each{g, iota{n}, rv, id_labels}, tup{
    # Read and possibly mask
    {i, v, lbl} => {
      v = load{*V~~end, i}
      def j = i+1
      if (j==n or j*vw >= rem) {
        v = homBlend{idv, v, maskOf{V, rem-i*vw}}
        goto{lbl}
      }
    },
    # Set to identity
    {i,v,lbl} => { if (i>0) v=idv; setlabel{lbl} }
  }}

  while (x < end) {
    rv = each{{v,i} => op{v, load{*V~~x, i}}, rv, iota{n}}
    x += step
  }

  # In-vector reduction on shape set,wid
  def done = makelabel{}
  if (set > 1) {
    # Shuffle uses byte indices
    def ls = 16; def ms = ls-1; def S = [ls]i8      # One lane
    def ns = arch_defvw / width{i8}; def I = [ns]i8 # One vector
    def has_lanes = ns>ls
    def iblend{a,b,m} = V~~homBlend{I~~a, I~~b, m}
    vms := I**ms
    viota := make{I, iota{ns}}
    hiota := viota & vms
    ws := wid*(width{T}/8) # Bytes in a row
    s := (set+1)/2         # Number of rows after halving
    k := s*ws              # Corresponding number of bytes
    def finish_step{} = {
      if (s==1) goto{done}
      set = s
      s = (s+1)/2
      k = s*ws
    }
    def nh = n/2+1
    @unroll (mi to nh+has_lanes) { def m = nh-mi  # reverse, m in [n/2+1,1-has_lanes]
      while (k >= (if (m>0) m*ns else ls)) {      # m==0 used for 1-lane offset
        o := k & (ns - 1)
        vo := I**cast_i{i8, o & ms}
        selmask := hiota < vo
        selind  := (hiota + vo) & vms
        def nv = min{m+1, n-m}  # Number of vectors to change
        @unroll (i from m+(m+1)>>1 to min{m+nv, n}) {
          def v = tupsel{i, rv}
          v = iblend{v, idv, viota >= I**cast_i{i8,set*ws-i*ns}}
        }
        @unroll (i to min{m+1, n-m}) {
          {a, b} := tupsel{i + tup{m, m+1}, merge{rv, tup{idv}}}
          if (has_lanes) {
            h := shufHalves{a,b, 16b21}
            if (o<ls) b = h; else a = h
          }
          def r = tupsel{i, rv}
          r = op{r, sel{S, iblend{a, b, selmask}, selind}}
        }
        finish_step{}
      }
    }
    # Down to one vector; reduce to a lane
    def v = tupsel{0, rv}
    while (1) {
      v = iblend{idv, v, I~~maskOf{I, set*ws}}
      t := if (has_lanes) iblend{v, shuf{[4]i64, v, 4b1032}, maskOf{I, k}} else v
      v = op{v, sel{S, t, (hiota + I**cast_i{i8, k}) & vms}}
      finish_step{}
    }
  }
  setlabel{done}
  rv  # Caller writes
}

fn insert_assoc{T, op, id0}(r:*void, x:*void, len:u64, width:u64) : void = {
  def id = if (ksym{id0}) emit{T, '', id0} else T~~id0
  def rv = insert_assoc_reg{T, op, id, x, len, width}

  # Write results
  def V = type{tupsel{0,rv}}
  def vw = vcount{V}
  rp := *V~~r
  lastv := tupsel{0, rv}
  i:u64 = 0
  each{
    {v} => {
      if ((i+1)*vw >= width) goto{'last'}
      store{rp, i, lastv}
      ++i; lastv = v
    },
    slice{rv, 1}
  }
  setlabel{'last'}
  homMaskStoreF{rp+i, maskOf{V, width-i*vw}, lastv}
}

def maxvalue{T==f64} = 'INFINITY'
exportT{
  'avx2_insert_min',
  each{{T} => insert_assoc{T, min, maxvalue{T}}, tup{i8,i16,i32,f64}}
}
